{
 "metadata": {
  "name": "",
  "signature": "sha256:f47bff7f10c9a6124a7cfc07b747d8dabf81cdbdbf76b04d9ddf776d3692922d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import menpo.io as mio\n",
      "from menpo.feature import no_op, igo, hog, sparse_hog, lbp\n",
      "\n",
      "# method to load a database\n",
      "def load_database(path_to_images, crop_percentage, max_images=None):\n",
      "    images = []\n",
      "    # load landmarked images\n",
      "    for i in mio.import_images(path_to_images, max_images=max_images, verbose=True):\n",
      "        # crop image\n",
      "        i.crop_to_landmarks_proportion_inplace(crop_percentage)\n",
      "        \n",
      "        # convert it to grayscale if needed\n",
      "        if i.n_channels == 3:\n",
      "            i = i.as_greyscale(mode='luminosity')\n",
      "            \n",
      "        # append it to the list\n",
      "        images.append(no_op(i))\n",
      "    return images"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "images = load_database('/mnt/data/nontas/train200/', 0.5)\n",
      "n_channels = images[0].n_channels\n",
      "patch_shape = (17, 17)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from menpo.visualize import print_dynamic, progress_bar_str\n",
      "\n",
      "def extract_patch_vectors(image, group, label, patch_size,\n",
      "                          normalize_patches=False):\n",
      "    r\"\"\"\n",
      "    returns a numpy.array of size (16*16*36) x 68\n",
      "    \"\"\"\n",
      "    # extract patches\n",
      "    patches = image.extract_patches_around_landmarks(\n",
      "        group=group, label=label, patch_size=patch_size,\n",
      "        as_single_array=not normalize_patches)\n",
      "\n",
      "    # vectorize patches\n",
      "    if normalize_patches:\n",
      "        # initialize output matrix\n",
      "        patches_vectors = np.empty(\n",
      "            (np.prod(patches[0].shape) * patches[0].n_channels, len(patches)))\n",
      "\n",
      "        # extract each vector\n",
      "        for p in range(len(patches)):\n",
      "            # normalize part\n",
      "            patches[p].normalize_norm_inplace()\n",
      "\n",
      "            # extract vector\n",
      "            patches_vectors[:, p] = patches[p].as_vector()\n",
      "    else:\n",
      "        # initialize output matrix\n",
      "        patches_vectors = np.empty((np.prod(patches.shape[1:]),\n",
      "                                    patches.shape[0]))\n",
      "\n",
      "        # extract each vector\n",
      "        for p in range(patches.shape[0]):\n",
      "            patches_vectors[:, p] = patches[p, ...].ravel()\n",
      "\n",
      "    # return vectorized parts\n",
      "    return patches_vectors\n",
      "\n",
      "\n",
      "def _warp_images_joan(images, group, label, patch_size, level_str, verbose):\n",
      "    r\"\"\"\n",
      "    returns numpy.array of size (16*16*36) x n_images x 68\n",
      "    \"\"\"\n",
      "    # find length of each patch and number of points\n",
      "    patches_len = np.prod(patch_size) * images[0].n_channels\n",
      "    n_points = images[0].landmarks[group][label].n_points\n",
      "\n",
      "    # initialize an output numpy array\n",
      "    patches_array = np.empty((patches_len, n_points, len(images)))\n",
      "\n",
      "    # extract parts\n",
      "    for c, i in enumerate(images):\n",
      "        # print progress\n",
      "        if verbose:\n",
      "            print_dynamic('{}Extracting patches from images - {}'.format(\n",
      "                level_str,\n",
      "                progress_bar_str(float(c + 1) / len(images),\n",
      "                                 show_bar=False)))\n",
      "\n",
      "        # extract patches from this image\n",
      "        patches_vectors = extract_patch_vectors(\n",
      "            i, group=group, label=label, patch_size=patch_size,\n",
      "            normalize_patches=False)\n",
      "\n",
      "        # store\n",
      "        patches_array[..., c] = patches_vectors\n",
      "\n",
      "    # rollaxis and return\n",
      "    return np.rollaxis(patches_array, 2, 1)\n",
      "\n",
      "def _build_appearance_model_joan(warped_images, n_appearance_parameters, level_str, verbose):\n",
      "    # build appearance model\n",
      "    if verbose:\n",
      "        print_dynamic('{}Training appearance distribution per '\n",
      "                      'patch'.format(level_str))\n",
      "    n_points = warped_images.shape[-1]\n",
      "    patch_len = warped_images.shape[0]\n",
      "    app_len = patch_len * n_points\n",
      "    app_mean = np.empty(app_len)\n",
      "    app_cov = np.zeros((app_len, app_len))\n",
      "    for e in range(n_points):\n",
      "        # print progress\n",
      "        if verbose:\n",
      "            print_dynamic('{}Training appearance distribution '\n",
      "                          'per patch - {}'.format(\n",
      "                          level_str,\n",
      "                          progress_bar_str(float(e + 1) / n_points,\n",
      "                                           show_bar=False)))\n",
      "        # find indices in target mean and covariance matrices\n",
      "        i_from = e * patch_len\n",
      "        i_to = (e + 1) * patch_len\n",
      "        # compute and store mean\n",
      "        app_mean[i_from:i_to] = np.mean(warped_images[..., e], axis=1)\n",
      "        # compute and store covariance\n",
      "        cov_mat = np.cov(warped_images[..., e])\n",
      "        s, v, d = np.linalg.svd(cov_mat)\n",
      "        s = s[:, :n_appearance_parameters]\n",
      "        v = v[:n_appearance_parameters]\n",
      "        d = d[:n_appearance_parameters, :]\n",
      "        app_cov[i_from:i_to, i_from:i_to] = s.dot(np.diag(1/v)).dot(d)\n",
      "    return app_mean, app_cov"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cvpr15.builder import _build_appearance_model, _warp_images\n",
      "import timeit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "warped_images1 = _warp_images_joan(images, 'PTS', 'all', patch_shape, 'Joan: ', True)\n",
      "app1 = _build_appearance_model_joan(warped_images1, 200, 'Joan: ', True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "warped_images2 = _warp_images(images, 'PTS', 'all', patch_shape, 'Nontas: ', True)\n",
      "app2 = _build_appearance_model(warped_images2, 68, patch_shape, n_channels, 200, 'Nontas: ', True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print app1[0].shape, app1[1].shape\n",
      "print app2[0].shape, app2[1].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.array_equal(app1[0], app2[0])\n",
      "print np.array_equal(app1[1], app2[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print warped_images1.shape\n",
      "print warped_images2.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = 37\n",
      "i = 10\n",
      "\n",
      "from menpo.image import Image\n",
      "import numpy as np\n",
      "%matplotlib inline\n",
      "m1 = warped_images1[:, i, p].reshape(patch_shape[0], patch_shape[1], n_channels)\n",
      "Image(m1).view(channels=0)\n",
      "\n",
      "patch_len = np.prod(patch_shape) * n_channels\n",
      "i_from = p * patch_len\n",
      "i_to = (p + 1) * patch_len\n",
      "m2 = warped_images2[i_from:i_to, i].reshape(patch_shape[0], patch_shape[1], n_channels)\n",
      "Image(m2).view_new(channels=0)\n",
      "\n",
      "print np.array_equal(m1, m2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e = 37\n",
      "d1 = np.cov(warped_images1[..., e])\n",
      "\n",
      "patch_len = np.prod(patch_shape) * n_channels\n",
      "i_from = e * patch_len\n",
      "i_to = (e + 1) * patch_len\n",
      "d2 = np.cov(warped_images2[i_from:i_to, :])\n",
      "\n",
      "print np.array_equal(d1, d2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patch_len1 = warped_images1.shape[0]\n",
      "patch_len2 = np.prod(patch_shape) * n_channels\n",
      "\n",
      "print patch_len1, patch_len2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}